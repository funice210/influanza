# -*- coding: utf-8 -*-
"""
Created on Tue May 22 14:12:40 2018

@author: kc
"""

import numpy
import pandas as pd
from keras.utils import np_utils
from sklearn import preprocessing
numpy.random.seed(10)


all_df = pd.read_csv('E:\\probes_GSE52428matrix -500_out.txt',sep = '\t',encoding = 'utf-8')
cols=['Label','ID',
'202985_s_at',
'220784_s_at',
'212737_at',
'217860_at',
'216379_x_at',
'209422_at',
'207697_x_at',
'220051_at',
'205671_s_at',
'219382_at',
'219137_s_at',
'205905_s_at',
'213405_at',
'207815_at',
'35820_at',
'208866_at',
'209374_s_at',
'205821_at',
'218928_s_at',
'204142_at',
'217979_at',
'203467_at',
'201572_x_at',
'209828_s_at',
'219547_at',
'202630_at',
'210763_x_at',
'205708_s_at',
'203470_s_at',
'212527_at',
'204839_at',
'207759_s_at',
'210102_at',
'213348_at',
'217792_at',
'220068_at',
'204711_at',
'215838_at',
'218329_at',
'203620_s_at',
'215891_s_at',
'214022_s_at',
'207072_at',
'210789_x_at',
'209771_x_at',
'202178_at',
'213645_at',
'202306_at',
'204143_s_at',
'206478_at',
'203415_at',
'209994_s_at',
'217466_x_at',
'207819_s_at',
'210659_at',
'208594_x_at',
'212017_at',
'219532_at',
'217403_s_at',
'213567_at',
'211010_s_at',
'216733_s_at',
'212504_at',
'210968_s_at',
'202086_at',
'218276_s_at',
'48659_at',
'213215_at',
'203269_at',
'209920_at',
'205267_at',
'210993_s_at',
'202693_s_at',
'203113_s_at',
'222315_at',
'215211_at',
'219534_x_at',
'212945_s_at',
'221484_at',
'218458_at',
'209831_x_at',
'221688_s_at',
'204211_x_at',
'201230_s_at',
'200973_s_at',
'208914_at',
'211067_s_at',
'202981_x_at',
'208892_s_at',
'217968_at',
'219961_s_at',
'218421_at',
'206759_at',
'209117_at',
'209906_at',
'203521_s_at',
'213182_x_at',
'203246_s_at',
'210137_s_at',
'218170_at',
'201612_at',
'209659_s_at',
'205987_at',
'204119_s_at',
'213772_s_at',
'213183_s_at',
'219667_s_at',
'218795_at',
'212826_s_at',
'212205_at',
'208262_x_at',
'211336_x_at',
'204328_at',
'205437_at',
'209367_at',
'205692_s_at',
'207100_s_at',
'205099_s_at',
'214531_s_at',
'213694_at',
'215451_s_at',
'202087_s_at',
'212121_at',
'204012_s_at',
'205997_at',
'218310_at',
'202905_x_at',
'212658_at',
'35156_at',
'211976_at',
'211988_at',
'203455_s_at',
'217928_s_at',
'202931_x_at',
'221897_at',
'212285_s_at',
'209058_at',
'213625_at',
'219128_at',
'212759_s_at',
'216945_x_at',
'206126_at',
'207500_at',
'212501_at',
'203582_s_at',
'221239_s_at',
'209457_at',
'213274_s_at',
'209939_x_at',
'200811_at',
'200972_at',
'214048_at',
'209059_s_at',
'204004_at',
'201811_x_at',
'213716_s_at',
'214790_at',
'213093_at',
'36553_at',
'210046_s_at',
'212090_at',
'202270_at',
'219120_at',
'206398_s_at',
'208052_x_at',
'65472_at',
'219062_s_at',
'212510_at',
'202284_s_at',
'204581_at',
'203135_at',
'209093_s_at',
'200610_s_at',
'AFFX-HUMISGF3A/M97935_3_at',
'219848_s_at',
'213161_at',
'217518_at',
'219497_s_at',
'205992_s_at',
'212206_s_at',
'209539_at',
'219849_at',
'218652_s_at',
'202271_at',
'219073_s_at',
'202380_s_at',
'200631_s_at',
'212201_at',
'201601_x_at',
'208965_s_at',
'213750_at',
'219607_s_at',
'210356_x_at',
'202798_at',
'205067_at',
'212426_s_at',
'209993_at',
'208836_at',
'209682_at',
'213851_at',
'203537_at',
'218168_s_at',
'201479_at',
'215823_x_at',
'202145_at',
'221878_at',
'210784_x_at',
'207324_s_at',
'212608_s_at',
'219818_s_at',
'221020_s_at',
'209580_s_at',
'220035_at',
'213278_at',
'200887_s_at',
'208722_s_at',
'211937_at',
'202548_s_at',
'209307_at',
'218154_at',
'200649_at',
'210201_x_at',
'201518_at',
'203848_at',
'217418_x_at',
'202365_at',
'218140_x_at',
'214472_at',
'206133_at',
'207000_s_at',
'213002_at',
'208975_s_at',
'214047_s_at',
'213674_x_at',
'221428_s_at',
'205297_s_at',
'216559_x_at',
'203909_at',
'210218_s_at',
'212229_s_at',
'211729_x_at',
'221475_s_at',
'209583_s_at',
'213489_at',
'219202_at',
'209304_x_at',
'201054_at',
'201515_s_at',
'202656_s_at',
'214643_x_at',
'204998_s_at',
'218247_s_at',
'218237_s_at',
'212498_at',
'214280_x_at',
'219014_at',
'217940_s_at',
'221123_x_at',
'219352_at',
'211135_x_at',
'221645_s_at',
'207339_s_at',
'220160_s_at',
'212402_at',
'203128_at',
'207023_x_at',
'201788_at',
'210190_at',
'212704_at',
'221044_s_at',
'200734_s_at',
'219627_at',
'209630_s_at',
'204199_at',
'218552_at',
'202265_at',
'203568_s_at',
'212590_at',
'210592_s_at',
'216950_s_at',
'210336_x_at',
'217987_at',
'203569_s_at',
'212539_at',
'213293_s_at',
'212314_at',
'221081_s_at',
'204612_at',
'202561_at',
'36564_at',
'201343_at',
'206710_s_at',
'210225_x_at',
'218495_at',
'213218_at',
'210448_s_at',
'205241_at',
'205322_s_at',
'203148_s_at',
'203250_at',
'209969_s_at',
'211623_s_at',
'210152_at',
'40569_at',
'207104_x_at',
'217846_at',
'209501_at',
'201688_s_at',
'206553_at',
'218120_s_at',
'200823_x_at',
'202869_at',
'213534_s_at',
'210223_s_at',
'212640_at',
'201670_s_at',
'211776_s_at',
'201993_x_at',
'211794_at',
'212622_at',
'214163_at',
'214167_s_at',
'211013_x_at',
'213213_at',
'210017_at',
'217988_at',
'222154_s_at',
'219806_s_at',
'217719_at',
'209761_s_at',
'212266_s_at',
'212508_at',
'204985_s_at',
'216565_x_at',
'207826_s_at',
'212131_at',
'213326_at',
'203922_s_at',
'213410_at',
'208966_x_at',
'219481_at',
'203038_at',
'218149_s_at',
'201600_at',
'218750_at',
'203595_s_at',
'210202_s_at',
'214511_x_at',
'201258_at',
'200716_x_at',
'209762_x_at',
'34689_at',
'202100_at',
'213047_x_at',
'201995_at',
'200597_at',
'221768_at',
'221860_at',
'211044_at',
'208912_s_at',
'201537_s_at',
'201855_s_at',
'201272_at',
'206332_s_at',
'218370_s_at',
'218079_s_at',
'44673_at',
'203380_x_at',
'212352_s_at',
'208751_at',
'200810_s_at',
'218429_s_at',
'203773_x_at',
'211666_x_at',
'205098_at',
'210224_at',
'211727_s_at',
'216570_x_at',
'205483_s_at',
'200036_s_at',
'201592_at',
'219648_at',
'210425_x_at',
'208012_x_at',
'211710_x_at',
'205353_s_at',
'205170_at',
'AFFX-HUMISGF3A/M97935_MB_at',
'40189_at',
'200689_x_at',
'213988_s_at',
'212672_at',
'218543_s_at',
'200081_s_at',
'202646_s_at',
'201798_s_at',
'218456_at',
'206503_x_at',
'200089_s_at',
'204204_at',
'218559_s_at',
'211456_x_at',
'211014_s_at',
'214453_s_at',
'203026_at',
'200024_at',
'206513_at',
'212160_at',
'204352_at',
'201641_at',
'214042_s_at',
'202430_s_at',
'218016_s_at',
'206491_s_at',
'200705_s_at',
'213294_at',
'212845_at',
'210027_s_at',
'203882_at',
'214323_s_at',
'202307_s_at',
'212675_s_at',
'215963_x_at',
'210705_s_at',
'211941_s_at',
'204232_at',
'203153_at',
'216202_s_at',
'218999_at',
'212807_s_at',
'202969_at',
'211005_at',
'221680_s_at',
'202968_s_at',
'201217_x_at',
'53720_at',
'201154_x_at',
'204279_at',
'204747_at',
'205055_at',
'200628_s_at',
'208392_x_at',
'204858_s_at',
'203127_s_at',
'201458_s_at',
'219684_at',
'220960_x_at',
'209593_s_at',
'33304_at',
'221726_at',
'212232_at',
'217933_s_at',
'206011_at',
'204804_at',
'215495_s_at',
'221050_s_at',
'217922_at',
'204439_at',
'211366_x_at',
'211929_at',
'211938_at',
'205552_s_at',
'221965_at',
'221816_s_at',
'200858_s_at',
'35254_at',
'212185_x_at',
'202688_at',
'219519_s_at',
'209240_at',
'202269_x_at',
'205585_at',
'208073_x_at',
'211012_s_at',
'204415_at',
'201649_at',
'221345_at',
'202446_s_at',
'208974_x_at',
'219403_s_at',
'214059_at',
'201064_s_at',
'200629_at',
'208436_s_at',
'205875_s_at',
'208087_s_at',
'216243_s_at',
'204994_at',
'212657_s_at',
'207713_s_at',
'204972_at',
'218400_at',
'211883_x_at',
'210797_s_at',
'203159_at',
'200986_at',
'205660_at',
'203567_s_at',
'213797_at',
'219863_at']

all_df=all_df[cols]
msk = numpy.random.rand(len(all_df)) < 0.8
train_df = all_df[msk]
test_df = all_df[~msk]
print('total:',len(all_df),
      'train:',len(train_df),
      'test:',len(test_df))

def PreprocessData(raw_df):
    df=raw_df.drop(['ID'], axis=1)#移除ID欄位
    ndarray = df.values#dataframe轉換為array
    Features = ndarray[:,1:] 
    Label = ndarray[:,0]

    minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))
    scaledFeatures=minmax_scale.fit_transform(Features)    
    scaledFeatures[2:1]
    return scaledFeatures,Label
    
train_Features,train_Label=PreprocessData(train_df)
test_Features,test_Label=PreprocessData(test_df)


Train4D_train_Features=train_Features.reshape(train_Features.shape[0],20,25,1).astype('float32')
Test4D_test_Features=test_Features.reshape(test_Features.shape[0],20,25,1).astype('float32')

train_LabelOneHot = np_utils.to_categorical(train_Label)
test_LabelOneHot = np_utils.to_categorical(test_Label)

from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D
import tensorflow as tf
import keras.backend.tensorflow_backend as KTF

KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'cpu':0})))
model = Sequential()
#建立卷積層1與池化層1


model.add(Conv2D(filters=16,#建立16個濾鏡filter weight
                 kernel_size=(5,5),#設定每個濾鏡5X5大小
                 padding='same',#此設定讓卷積運算，產生的卷積影像大小不變
                 input_shape=(150,150,1),#第1 2維度:代表輸入的影像形狀150x150大小，第3維度:最後維度是1
                 activation='relu'))#設定ReLU激活函數
model.add(MaxPooling2D(pool_size=(2,5)))#縮減取樣，將16個150x150影像，縮小為16個75x75影像

#建立卷積層2與池化層2
model.add(Conv2D(filters=36,#建立36個濾鏡filter weight
                 kernel_size=(5,5),#設定每個濾鏡5X5大小
                 padding='same',#此設定讓卷積運算，產生的卷積影像大小不變
                 activation='relu'))#設定ReLU激活函數
model.add(MaxPooling2D(pool_size=(5,5)))#縮減取樣，將36個75x75影像，縮小為36個25x25影像
model.add(Dropout(0.25))#訓練迭代時，隨機在神經網路中放棄25%的神經元


#建立平坦層
model.add(Flatten())#將36個25X25影像，轉換為1維向量，長度是36X25X25=22500
#建立隱藏層
model.add(Dense(1000, kernel_initializer='uniform', activation='relu'))#共有50個神經元

#建立輸出層
model.add(Dense(800, kernel_initializer='uniform', activation='relu'))#共有30個神經元
model.add(Dropout(0.5))#訓練迭代時，隨機在神經網路中放棄50%的神經元，避免overfitting
model.add(Dense(700, kernel_initializer='uniform', activation='relu'))#共有30個神經元

model.add(Dense(500, kernel_initializer='uniform', activation='relu'))#共有30個神經元
model.add(Dense(2, kernel_initializer='uniform', activation='softmax'))#輸出2個神經元，使用softmax激活函數
print(model.summary())




model.compile(loss='categorical_crossentropy', 
              optimizer='adam', metrics=['accuracy'])

train_history=model.fit(x=Train4D_train_Features,
                        y=train_LabelOneHot,validation_split=0.2,
                        epochs=30,batch_size=100,verbose=2)
scores=model.evaluate(x=Train4D_train_Features,y=train_LabelOneHot)
print('accuracy=',scores[1])

"""all_Features,Label=PreprocessData(all_df)
all_probability=model.predict(all_Features)
pd=all_df
pd.insert(len(all_df.columns),'probability',all_probability)"""



import matplotlib.pyplot as plt
def show_train_history(train_history,train,validation):
    plt.plot(train_history.history[train])
    plt.plot(train_history.history[validation])
    plt.title('Train History')
    plt.ylabel('accuracy')
    plt.xlabel('Epoch')
    plt.legend(['train','validation',],loc='upper left')
    plt.show
"""'train_loss','validation_loss',"""
show_train_history(train_history,'acc','val_acc')
"""show_train_history(train_history,'loss','val_loss')"""
#del(model)
